{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple notebook to get ERA5 data for Kelmarsh wind farm\n",
    "\n",
    "We often need to fill in gaps for missing on site records. Having datasets like MERRA2 and ERA5 gives us a data source that can be used to build models to fill gaps.\n",
    "\n",
    "This notebook gets ERA5 data for the Kelmarsh wind farm in the UK at lat 52.401461, long -0.943105\n",
    "using information available from <br>\n",
    "CDS https://cds.climate.copernicus.eu/how-to-api\n",
    "\n",
    "\n",
    "This code will not work until you sign up for a cds account and follow instructions on page above to get your own api key.\n",
    "\n",
    "### Identify surrounding 4 grid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "# Set the display width\n",
    "pl.Config.set_tbl_cols(100)  # Set the number of columns to display\n",
    "pl.Config.set_tbl_width_chars(200)  # Set the width in characters\n",
    "import cdsapi\n",
    "from calendar import monthrange\n",
    "from pathlib import Path\n",
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_surrounding_grid_points(lat, lon, interval=0.25):\n",
    "    # Calculate the nearest grid point\n",
    "    nearest_lat = round(lat / interval) * interval\n",
    "    nearest_lon = round(lon / interval) * interval\n",
    "\n",
    "    # Calculate surrounding grid points\n",
    "    lat_points = [nearest_lat - interval, nearest_lat, nearest_lat + interval]\n",
    "    lon_points = [nearest_lon - interval, nearest_lon, nearest_lon + interval]\n",
    "\n",
    "    # Generate all combinations of surrounding grid points\n",
    "    surrounding_points = [(lat, lon) for lat in lat_points for lon in lon_points]\n",
    "    \n",
    "    return surrounding_points\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "\n",
    "    # Compute differences\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def get_closest_grid_points(lat, lon, num_points=4):\n",
    "    surrounding_points = get_surrounding_grid_points(lat, lon)\n",
    "    distances = [(point, haversine(lat, lon, point[0], point[1])) for point in surrounding_points]\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    closest_points = [point for point, distance in distances[:num_points]]\n",
    "    return closest_points\n",
    "\n",
    "# Example usage\n",
    "lat = 52.40\n",
    "lon = -0.943\n",
    "closest_points = get_closest_grid_points(lat, lon)\n",
    "# closest_points is used in next cell\n",
    "\n",
    "# Print the closest points and their distances\n",
    "for point in closest_points:\n",
    "    distance = np.round(haversine(lat, lon, point[0], point[1]), 3)\n",
    "    print(f'For point {point}, distance is {distance} km from Kelmarsh at {lat}, {lon}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data from CDS\n",
    "\n",
    "As noted above, you have to get an API key first from <br>\n",
    "CDS https://cds.climate.copernicus.eu/how-to-api\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_era5_data(year, month, closest_points, output_dir, max_retries=3):\n",
    "    # Initialize the CDS API client\n",
    "    c = cdsapi.Client()\n",
    "\n",
    "    # Get the number of days in the month\n",
    "    num_days = monthrange(year, month)[1]\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Calculate the expected range from the closest points\n",
    "    lat_min = min(point[0] for point in closest_points)\n",
    "    lat_max = max(point[0] for point in closest_points)\n",
    "    lon_min = min(point[1] for point in closest_points)\n",
    "    lon_max = max(point[1] for point in closest_points)\n",
    "\n",
    "    # Request ERA5 data with retry mechanism\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'format': 'netcdf',  # Options: 'grib' or 'netcdf'\n",
    "                    'variable': [\n",
    "                        '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind',\n",
    "                        'surface_pressure', '100m_u_component_of_wind', '100m_v_component_of_wind'\n",
    "                    ],\n",
    "                    'year': str(year),\n",
    "                    'month': f'{month:02d}',\n",
    "                    'day': [f'{day:02d}' for day in range(1, num_days + 1)],\n",
    "                    'time': [\n",
    "                        '00:00', '01:00', '02:00', '03:00', '04:00', '05:00',\n",
    "                        '06:00', '07:00', '08:00', '09:00', '10:00', '11:00',\n",
    "                        '12:00', '13:00', '14:00', '15:00', '16:00', '17:00',\n",
    "                        '18:00', '19:00', '20:00', '21:00', '22:00', '23:00',\n",
    "                    ],\n",
    "                    'area': [\n",
    "                        lat_max, lon_min, lat_min, lon_max,\n",
    "                    ],  # North, West, South, East\n",
    "                },\n",
    "                output_dir / f'era5_single_levels_{year}{month:02d}.nc'  # Output file name\n",
    "            )\n",
    "            print(f'Successfully downloaded data for {year}-{month:02d} into {output_dir}')\n",
    "            break  # Exit the loop if the download is successful\n",
    "        except Exception as e:\n",
    "            print(f'Failed to download data for {year}-{month:02d} on attempt {attempt + 1}: {e}')\n",
    "            if attempt < max_retries - 1:\n",
    "                print('Retrying...')\n",
    "                time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "            else:\n",
    "                print('Max retries reached. Moving to the next month.')\n",
    "\n",
    "# Example usage: Loop through a year and download data for each month\n",
    "year = 2020\n",
    "output_dir = Path('era5_data')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# closest_points should be defined in a previous cell\n",
    "# closest_points = [(52.25, -1.25), (52.25, -1.00), (52.25, -0.75), (52.50, -1.25)]\n",
    "\n",
    "for month in range(1, 13):\n",
    "    download_era5_data(year, month, closest_points, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine nc files into polars df\n",
    "\n",
    "The data is in netcdf format, so we mine the nc files and make a polars df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_nc_files_to_polars_df(nc_files):\n",
    "    dfs = []\n",
    "    for nc_file in nc_files:\n",
    "        # Load the NetCDF file using xarray\n",
    "        ds = xr.open_dataset(nc_file)\n",
    "\n",
    "        # Convert xarray.Dataset to a Pandas DataFrame\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "\n",
    "        # Convert Pandas DataFrame to Polars DataFrame\n",
    "        pl_df = pl.from_pandas(df)\n",
    "\n",
    "        # Append to the list of DataFrames\n",
    "        dfs.append(pl_df)\n",
    "\n",
    "    # Concatenate all Polars DataFrames\n",
    "    combined_df = pl.concat(dfs)\n",
    "    return combined_df\n",
    "\n",
    "# Example usage: Load all .nc files in the output directory\n",
    "output_dir = Path('era5_data')\n",
    "nc_files = list(output_dir.glob('*.nc'))\n",
    "\n",
    "# Load the NetCDF files into a Polars DataFrame\n",
    "polars_df = (load_nc_files_to_polars_df(nc_files)\n",
    "             .drop(['expver', 'number'])\n",
    "             .sort(['valid_time', 'latitude', 'longitude']))\n",
    "\n",
    "# rename to iec -25-2 naming convention\n",
    "polars_df = polars_df.rename({'u10':'HorWdU_10m', 'v10':'HorWdV_10m', \n",
    "                              'u100':'HorWdU_100m', 'v100':'HorWdV_100m', \n",
    "                              't2m':'EnvTmp_2m', 'sp':'EnvPres_0m'})\n",
    "\n",
    "# consider variables used and if it is reasonable to store as float32 instead of float64 as it takes up half the space in RAM and you can deal with larger datasets\n",
    "polars_df = polars_df.cast({cs.float():pl.Float32})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review data for completeness and reasonableness, and ts range\n",
    "print(polars_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(polars_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists\n",
    "cwd = Path.cwd()\n",
    "output_dir = cwd / 'output'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "polars_df.write_csv(output_dir / 'era5_data.csv', datetime_format='%Y-%m-%d %H:%M:%S')\n",
    "polars_df.write_parquet(output_dir / 'era5_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
