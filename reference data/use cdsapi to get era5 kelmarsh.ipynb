{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple notebook to get ERA5 data for Kelmarsh wind farm\n",
    "\n",
    "We often need to fill in gaps for missing on site records. Having datasets like MERRA2 and ERA5 gives us a data source that can be used to build models to fill gaps. This is a simplified example. A professional analyst would convert this notebook to a function that accepted the lat/long for a site, or would develop a loop to get multiple sites and would set the date range for data programmatically.  \n",
    "\n",
    "This notebook gets ERA5 data for the Kelmarsh wind farm in the UK at lat 52.401461, long -0.943105\n",
    "using information available from <br>\n",
    "CDS https://cds.climate.copernicus.eu/how-to-api\n",
    "\n",
    "\n",
    "This code will not work until you sign up for a cds account and follow the instructions on the CDS page above to get your own api key.\n",
    "\n",
    "Did you get your own api key yet?\n",
    "\n",
    "### Key libraries\n",
    "\n",
    "These are the key libraries and their revision level when this code was authored.  Consider including info about lirbary versions as comments in the script this is the first step in figuring out why the code you ran last month doesn't work this month. e discussions in entry level section of this repo for more details\n",
    "\n",
    "* python version: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]\n",
    "* numpy version: 1.26.2\n",
    "* polars version: 1.17.1\n",
    "* cdsapi version: 0.7.5\n",
    "* xarray version: 2023.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('python version:', __import__('sys').version)\n",
    "\n",
    "import math # to use math functions like radians, atan2\n",
    "from calendar import monthrange # to get the number of days in a month\n",
    "import time # for time.sleep() to wait for the API to respond\n",
    "from pathlib import Path # to work with file paths\n",
    "cwd = Path.cwd()\n",
    "\n",
    "import numpy as np\n",
    "print('numpy version:', np.__version__)\n",
    "import polars as pl # to use polars dataframes for our data\n",
    "print('polars version:', pl.__version__)\n",
    "import polars.selectors as cs # to use column selectors in polars\n",
    "# Set the display width\n",
    "pl.Config.set_tbl_cols(100)  # Set the number of polars df columns to display when printing\n",
    "pl.Config.set_tbl_width_chars(200)  # Set the width of polars df columns in characters when printing\n",
    "import cdsapi # to get the ERA5 data\n",
    "import pkg_resources\n",
    "cdsapi_version = pkg_resources.get_distribution(\"cdsapi\").version\n",
    "print('cdsapi version:', cdsapi_version)\n",
    "import xarray as xr # to read the netCDF files\n",
    "print('xarray version:', xr.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Identify surrounding 4 grid points\n",
    "\n",
    "ERA5 data is set up in a 0.25 deg grid for the entire world, we need to find either the closest point, or the surrounding points.  \n",
    "\n",
    "Since its just as easy to get surrounding points we do this, so we can understand the full context or what's going on around our point of interest (Kelmarsh wind farm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_surrounding_grid_points(lat, lon, interval=0.25):\n",
    "    # Calculate the nearest grid point\n",
    "    nearest_lat = np.round(lat / interval) * interval\n",
    "    nearest_lon = np.round(lon / interval) * interval\n",
    "\n",
    "    # Calculate surrounding grid points\n",
    "    lat_points = [nearest_lat - interval, nearest_lat, nearest_lat + interval]\n",
    "    lon_points = [nearest_lon - interval, nearest_lon, nearest_lon + interval]\n",
    "\n",
    "    # Generate all combinations of surrounding grid points\n",
    "    surrounding_points = [(lat, lon) for lat in lat_points for lon in lon_points]\n",
    "    \n",
    "    return surrounding_points\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "\n",
    "    # Compute differences\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def get_closest_grid_points(lat, lon, num_points=4):\n",
    "    surrounding_points = get_surrounding_grid_points(lat, lon)\n",
    "    distances = [(point, haversine(lat, lon, point[0], point[1])) for point in surrounding_points]\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    closest_points = [point for point, distance in distances[:num_points]]\n",
    "    return closest_points\n",
    "\n",
    "# Kelmarsh coordinates\n",
    "lat = 52.40\n",
    "lon = -0.943\n",
    "# find the ERA5 grid points closest to Kelmarsh - ERA5 data is on a 0.25 degree grid, both in latitude and longitude\n",
    "closest_points = get_closest_grid_points(lat, lon)\n",
    "\n",
    "\n",
    "# Print the closest points and their distances\n",
    "for point in closest_points:\n",
    "    distance = np.round(haversine(lat, lon, point[0], point[1]), 3)\n",
    "    print(f'For point {point}, distance is {distance} km from Kelmarsh at {lat}, {lon}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data from CDS\n",
    "\n",
    "As noted above, you have to get an API key first from <br>\n",
    "CDS https://cds.climate.copernicus.eu/how-to-api\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_era5_data(year, month, closest_points, output_dir, max_retries=3):\n",
    "    # Initialize the CDS API client\n",
    "    c = cdsapi.Client()\n",
    "\n",
    "    # Get the number of days in the month\n",
    "    num_days = monthrange(year, month)[1]\n",
    "\n",
    "    # Ensure the output directory exists, create if not\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Calculate the expected range from the closest points\n",
    "    lat_min = min(point[0] for point in closest_points)\n",
    "    lat_max = max(point[0] for point in closest_points)\n",
    "    lon_min = min(point[1] for point in closest_points)\n",
    "    lon_max = max(point[1] for point in closest_points)\n",
    "\n",
    "    # Request ERA5 data with retry mechanism\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'format': 'netcdf',  # Options: 'grib' or 'netcdf'\n",
    "                    'variable': [\n",
    "                        '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind',\n",
    "                        'surface_pressure', '100m_u_component_of_wind', '100m_v_component_of_wind'\n",
    "                    ],\n",
    "                    'year': str(year),\n",
    "                    'month': f'{month:02d}',\n",
    "                    'day': [f'{day:02d}' for day in range(1, num_days + 1)],\n",
    "                    'time': [\n",
    "                        '00:00', '01:00', '02:00', '03:00', '04:00', '05:00',\n",
    "                        '06:00', '07:00', '08:00', '09:00', '10:00', '11:00',\n",
    "                        '12:00', '13:00', '14:00', '15:00', '16:00', '17:00',\n",
    "                        '18:00', '19:00', '20:00', '21:00', '22:00', '23:00',\n",
    "                    ],\n",
    "                    'area': [\n",
    "                        lat_max, lon_min, lat_min, lon_max,\n",
    "                    ],  # North, West, South, East\n",
    "                },\n",
    "                output_dir / f'era5_single_levels_{year}{month:02d}.nc'  # Output file name\n",
    "            )\n",
    "            print(f'Successfully downloaded data for {year}-{month:02d} into {output_dir}')\n",
    "            break  # Exit the loop if the download is successful\n",
    "        except Exception as e:\n",
    "            print(f'Failed to download data for {year}-{month:02d} on attempt {attempt + 1}: {e}')\n",
    "            if attempt < max_retries - 1:\n",
    "                print('Retrying...')\n",
    "                time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "            else:\n",
    "                print('Max retries reached. Moving to the next month.')\n",
    "\n",
    "# Example usage: Loop through months of a year and download data for each month to our directory\n",
    "output_dir = cwd / 'era5_netcdf_files'\n",
    "year = 2020\n",
    "for month in range(1, 13):\n",
    "    download_era5_data(year, month, closest_points, output_dir)\n",
    "    # CDS data is in high demand and it's a busy site. Code can take 10x longer to run during European work hours.\n",
    "    # From the US, in the evening, this code may take 3-5 minutes to run.\n",
    "    # from the US, in the morning, this code may take 30-50 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine nc files into polars df\n",
    "\n",
    "The data is in netcdf format, so we mine the nc files and make a polars df\n",
    "\n",
    "Why polars?  It's faster, and it more closely follows rules for data structures being in a table format. The syntax is also easier to comprehend.\n",
    "\n",
    "And it's faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_nc_files_to_era5_data(nc_files):\n",
    "    \n",
    "    dfs = []\n",
    "    for nc_file in nc_files:\n",
    "        # Load the NetCDF file using xarray\n",
    "        ds = xr.open_dataset(nc_file)\n",
    "        # Convert xarray.Dataset to a Pandas DataFrame\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        # Convert Pandas DataFrame to Polars DataFrame\n",
    "        pl_df = pl.from_pandas(df)\n",
    "        # Append to the list of DataFrames\n",
    "        dfs.append(pl_df)\n",
    "    # Concatenate all Polars DataFrames\n",
    "    combined_df = pl.concat(dfs)\n",
    "    return combined_df\n",
    "\n",
    "# make a list of all .nc files downloaded in previous step\n",
    "# uses same output_dir as previous step\n",
    "nc_files = list(output_dir.glob('*.nc'))\n",
    "\n",
    "# Load the NetCDF files into a Polars DataFrame, then clean up \n",
    "era5_data = (load_nc_files_to_era5_data(nc_files) # returns a polars dataframe\n",
    "             .drop(['expver', 'number']) # drops the columns 'expver' and 'number' which didn't have data\n",
    "             # Date, TimeStamp, latitude, longitude not in table of accepted abbreviations in section 4 of IEC 61400-25-2, \n",
    "             # so used section 7.2.4.2 name for TimeStamp, appending UTC to avoid confusion with local time\n",
    "             # and table 45 names for latitude and longitude\n",
    "             .rename({'valid_time':'TimeStamp_UTC', 'latitude':'latitude', 'longitude':'longitude', # lat/long names kept\n",
    "                      'u10':'HorWdU_Alt10m', 'v10':'HorWdV_Alt10m', # some signals marked with 10m meaning 10 minutes,  \n",
    "                      'u100':'HorWdU_Alt100m', 'v100':'HorWdV_Alt100m', # so add Alt so 10m is altitude AGL above ground level\n",
    "                      't2m':'EnvTmp_Alt2m', 'sp':'EnvPres_Alt0m'})\n",
    "             .with_columns(pl.col('TimeStamp_UTC').dt.cast_time_unit('ms').alias('TimeStamp_UTC')) # put ts in ms, needs to be consistent later for joins\n",
    "             .sort(['TimeStamp_UTC', 'latitude', 'longitude'])\n",
    "             # consider variables used and if it is reasonable to store as float32 instead of float64 as it takes up \n",
    "             # half the space in RAM and you can deal with larger datasets\n",
    "             # the command below selects columns that are type float (32 or 64) and casts them to float32\n",
    "             .cast({cs.float():pl.Float32}) )\n",
    "\n",
    "# running polars data manipulations in a single statement allows the query optimizer to work more effectively, speeding execution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review data for completeness and reasonableness, and ts range\n",
    "print(era5_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(era5_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists, create it if not\n",
    "output_dir = cwd / 'era5_data'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "era5_data.write_csv(output_dir / 'era5_data.csv', datetime_format='%Y-%m-%d %H:%M:%S')\n",
    "era5_data.write_parquet(output_dir / 'era5_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
